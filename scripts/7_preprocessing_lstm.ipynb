{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preprocessing for LSTM\n",
    "  * Preprocessing with TimeSeries data format For use as input to the LSTM model\n",
    "\n",
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\"\"\"\n",
    "    1) import package\n",
    "\"\"\"\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pathlib\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import traceback\n",
    "from tqdm import tqdm\n",
    "from datetime import timedelta\n",
    "from _utils.preprocessing_lstm import *\n",
    "from _utils.customlogger import customlogger as CL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\"\"\"\n",
    "    2) loading config\n",
    "\"\"\"\n",
    "current_dir = pathlib.Path.cwd()\n",
    "parent_dir = current_dir.parent\n",
    "\n",
    "with open(parent_dir.joinpath(\"config.json\")) as file:\n",
    "    cfg = json.load(file)\n",
    "with open(parent_dir.joinpath(\"config_params.json\")) as file:\n",
    "    params = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\"\"\"\n",
    "    3) load information \n",
    "\"\"\"\n",
    "current_date = cfg[\"working_date\"]\n",
    "curr_file_name = os.path.splitext(os.path.basename(os.path.abspath('')))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\"\"\"\n",
    "    4) create Logger\n",
    "\"\"\"\n",
    "log = CL(\"custom_logger\")\n",
    "pathlib.Path.mkdir(pathlib.Path('{}/_log/'.format(parent_dir)), mode=0o777, parents=True, exist_ok=True)\n",
    "log = log.create_logger(file_name=\"../_log/{}.log\".format(curr_file_name), mode=\"a\", level=\"DEBUG\")  \n",
    "log.debug('start {}'.format(curr_file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resampling_4w(df):\n",
    "    return df.groupby('unique_id').apply(lambda x : x.set_index('concept_date').resample('7d').last().reset_index()).reset_index(drop=True)\n",
    "\n",
    "def get_time_stamp(df):\n",
    "    return int(len(df)/len(df.unique_id.unique()))\n",
    "\n",
    "def remove_special_characters(str):\n",
    "    import re\n",
    "    return re.sub('[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》]','', str)\n",
    "\n",
    "def save_single_concept_bar_plot(dir, df, concept_id, concept_name):\n",
    "    import seaborn as sns\n",
    "    import textwrap\n",
    "    fig=plt.figure()\n",
    "    plt.rcParams['figure.figsize'] = [7.00, 3.50]\n",
    "    plt.rcParams['figure.autolayout'] = True\n",
    "    ax = sns.boxplot(data=df, x=\"sequence\", y=concept_id, hue='label')\n",
    "        # showcaps=False,                     # 박스 상단 가로라인 보이지 않기\n",
    "        # whiskerprops={'linewidth':0},       # 박스 상단 세로 라인 보이지 않기 \n",
    "        # showfliers=True                     # 박스 범위 벗어난 아웃라이어 표시하지 않기\n",
    "    concept_name_short = textwrap.shorten(concept_name, width=60, placeholder=\"...\")\n",
    "    ax.set(title='{} ( {} )'.format(concept_name_short, concept_id))\n",
    "    timestamp = get_time_stamp(df)\n",
    "    ax.set_xticklabels(['t - {}w'.format(i) for i in range(timestamp, 0, -1)])\n",
    "    plt.xlabel('time')\n",
    "    plt.ylabel('value')\n",
    "    \n",
    "    plt.savefig('{}/{}.png'.format(dir, concept_name), format='png',\n",
    "            dpi=300, facecolor='white', transparent=True,  bbox_inches='tight')\n",
    "    plt.show()\n",
    "        \n",
    "def save_all_features(dir, df, concept_dict):\n",
    "    concept_id_list = list(set(df.columns) & set(concept_dict.keys()))\n",
    "    for concept_id in concept_id_list:\n",
    "        concept_name = remove_special_characters(concept_dict[concept_id])\n",
    "        save_single_concept_bar_plot(dir, df, concept_id, concept_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runTask(outcome_name):\n",
    "    # In[ ]:\n",
    "    \"\"\"\n",
    "        (1) Set the folder path to load and save data\n",
    "    \"\"\"\n",
    "    importsql_data_dir    = pathlib.Path('{}/data/{}/importsql/{}/'.format(parent_dir, current_date, outcome_name))           # input file path\n",
    "    output_data_dir         = pathlib.Path('{}/data/{}/preprocess_lstm/{}/'.format(parent_dir, current_date, outcome_name))     # output file path\n",
    "    output_result_dir       = pathlib.Path('{}/result/{}/preprocess_lstm/{}/'.format(parent_dir, current_date, outcome_name))   # output file path (features)\n",
    "    pathlib.Path.mkdir(output_data_dir, mode=0o777, parents=True, exist_ok=True)\n",
    "    pathlib.Path.mkdir(output_result_dir, mode=0o777, parents=True, exist_ok=True)\n",
    "\n",
    "    # In[ ]:\n",
    "    \"\"\"\n",
    "        (2) Skip if there is no patient data\n",
    "    \"\"\"\n",
    "    if not pathlib.Path.exists(importsql_data_dir.joinpath('all_domain_df.txt')):\n",
    "        log.debug(f\"{outcome_name} data frame is empty\")\n",
    "        return\n",
    "    \n",
    "    # In[ ]:\n",
    "    \"\"\"\n",
    "        (3) read data frame\n",
    "    \"\"\"\n",
    "    all_domain_df = pd.read_csv(importsql_data_dir.joinpath('all_domain_df.txt'), low_memory=False)\n",
    "    print(all_domain_df.concept_domain.value_counts())\n",
    "    print('label 1 : ', len(all_domain_df[all_domain_df['label']==1].person_id.unique()))\n",
    "    print('label 0 : ', len(all_domain_df[all_domain_df['label']==0].person_id.unique()))\n",
    "    nCase = all_domain_df.loc[all_domain_df['label'] == 1].person_id.nunique()\n",
    "    if nCase < 20:\n",
    "        log.debug(f\"{outcome_name} case is less than 20\")\n",
    "        return\n",
    "    \n",
    "    # In[ ]:\n",
    "    \"\"\"\n",
    "        (4) use only necessary columns\n",
    "    \"\"\"\n",
    "    common_cols = ['person_id', 'age', 'sex', 'cohort_start_date', 'first_abnormal_date', 'concept_date', 'concept_id', 'concept_name', 'concept_value', 'concept_domain', 'label']\n",
    "    all_domain_df = all_domain_df[common_cols]\n",
    "\n",
    "    # In[ ]:\n",
    "    \"\"\"\n",
    "        (5) Remove feature used in outcome define\n",
    "    \"\"\"\n",
    "    drug_name = outcome_name\n",
    "    drug_concept_ids_excluded = map(int,cfg['drug'][drug_name]['@drug_concept_set'].split(','))\n",
    "    all_domain_df = all_domain_df.loc[~all_domain_df.concept_id.isin(drug_concept_ids_excluded)]\n",
    "    meas_concept_ids_excluded = map(int,[cfg['meas'][meas_name]['@meas_concept_id'] for meas_name in cfg['meas']])\n",
    "    all_domain_df = all_domain_df.loc[~all_domain_df.concept_id.isin(meas_concept_ids_excluded)]\n",
    "    \n",
    "    # ---------------------- check features ----------------------------\n",
    "    concept_list = []\n",
    "    nCaseInTotal = len(all_domain_df.loc[all_domain_df['label']==1,'person_id'].unique())\n",
    "    nControlInTotal =len(all_domain_df.loc[all_domain_df['label']==0,'person_id'].unique())\n",
    "\n",
    "    meas_df = all_domain_df.loc[all_domain_df.concept_domain=='meas'].reset_index(drop=True)\n",
    "    drug_df = all_domain_df.loc[all_domain_df.concept_domain=='drug'].reset_index(drop=True)\n",
    "    proc_df = all_domain_df.loc[all_domain_df.concept_domain=='proc'].reset_index(drop=True)\n",
    "    cond_df = all_domain_df.loc[all_domain_df.concept_domain=='cond'].reset_index(drop=True)\n",
    "\n",
    "    meas_df = meas_df.groupby('concept_id').apply(lambda x : filter_with_missing_rate(x, nCaseInTotal, nControlInTotal, threshold=0.1)).reset_index(drop=True)\n",
    "    drug_df = drug_df.groupby('concept_id').apply(lambda x : filter_with_missing_rate(x, nCaseInTotal, nControlInTotal, threshold=0.1)).reset_index(drop=True)\n",
    "    proc_df = proc_df.groupby('concept_id').apply(lambda x : filter_with_missing_rate(x, nCaseInTotal, nControlInTotal, threshold=0.1)).reset_index(drop=True)\n",
    "    cond_df = cond_df.groupby('concept_id').apply(lambda x : filter_with_missing_rate(x, nCaseInTotal, nControlInTotal, threshold=0.1)).reset_index(drop=True)\n",
    "\n",
    "    meas_concept_df = meas_df.groupby('concept_id').apply(lambda x : filter_with_missing_rate_concept(x, nCaseInTotal, nControlInTotal, threshold=0.1)).reset_index(drop=True)\n",
    "    drug_concept_df = drug_df.groupby('concept_id').apply(lambda x : filter_with_missing_rate_concept(x, nCaseInTotal, nControlInTotal, threshold=0.1)).reset_index(drop=True)\n",
    "    proc_concept_df = proc_df.groupby('concept_id').apply(lambda x : filter_with_missing_rate_concept(x, nCaseInTotal, nControlInTotal, threshold=0.1)).reset_index(drop=True)\n",
    "    cond_concept_df = cond_df.groupby('concept_id').apply(lambda x : filter_with_missing_rate_concept(x, nCaseInTotal, nControlInTotal, threshold=0.1)).reset_index(drop=True)\n",
    "\n",
    "    meas_concept_df['concept_domain'] = 'meas'\n",
    "    drug_concept_df['concept_domain'] = 'drug'\n",
    "    proc_concept_df['concept_domain'] = 'proc'\n",
    "    cond_concept_df['concept_domain'] = 'cond'\n",
    "    \n",
    "    all_domain_concept_df = pd.concat([meas_concept_df, drug_concept_df, proc_concept_df, cond_concept_df], axis=0, ignore_index=True)\n",
    "    all_domain_concept_df.to_csv('{}/{}_feature_2.csv'.format(output_result_dir, outcome_name), header=True, index=True)\n",
    "    # -------------------------------------------------------------------\n",
    "    \n",
    "    # @variable selection\n",
    "    meas_vars_df = variant_selection_paired_t_test(meas_df)\n",
    "    drug_vars_df = variant_selection_mcnemar(drug_df)\n",
    "    proc_vars_df = variant_selection_mcnemar(proc_df)\n",
    "    cond_vars_df = variant_selection_mcnemar(cond_df)\n",
    "\n",
    "    # @variable selection (Top 30 based on p Value)\n",
    "    #pd.options.display.precision = 3\n",
    "    meas_vars_df = meas_vars_df.sort_values(by='pvalue', ascending=True).reset_index(drop=True).head(30)\n",
    "    drug_vars_df = drug_vars_df.sort_values(by='pvalue', ascending=True).reset_index(drop=True).head(30)\n",
    "    proc_vars_df = proc_vars_df.sort_values(by='pvalue', ascending=True).reset_index(drop=True).head(30)\n",
    "    cond_vars_df = cond_vars_df.sort_values(by='pvalue', ascending=True).reset_index(drop=True).head(30)\n",
    "    print(len(meas_vars_df), len(drug_vars_df), len(proc_vars_df), len(cond_vars_df))\n",
    "    \n",
    "    meas_vars_df['concept_domain'] = 'meas'\n",
    "    drug_vars_df['concept_domain'] = 'drug'\n",
    "    proc_vars_df['concept_domain'] = 'proc'\n",
    "    cond_vars_df['concept_domain'] = 'cond'\n",
    "    all_domain_vars_df = pd.concat([meas_vars_df, drug_vars_df, proc_vars_df, cond_vars_df], axis=0, ignore_index=True)\n",
    "    # @variable selection (save)\n",
    "    all_domain_vars_df.to_csv('{}/{}_feature.csv'.format(output_result_dir, outcome_name), header=True, index=True)\n",
    "    # all_domain_vars_df = pd.read_csv('{}/{}_{}_feature.csv'.format(output_result_dir, outcome_name), index_col=False) #check\n",
    "\n",
    "    # @Extract only selected concepts from data frame\n",
    "    def extractSelectedConceptID(domain_df, concept_id_list):\n",
    "        extract_domain_df = domain_df[domain_df['concept_id'].isin(concept_id_list)]\n",
    "        print(len(concept_id_list), len(domain_df), len(extract_domain_df))\n",
    "        return extract_domain_df\n",
    "\n",
    "    meas_fs_df = extractSelectedConceptID(meas_df, meas_vars_df.concept_id.unique())\n",
    "    drug_fs_df = extractSelectedConceptID(drug_df, drug_vars_df.concept_id.unique())\n",
    "    proc_fs_df = extractSelectedConceptID(proc_df, proc_vars_df.concept_id.unique())\n",
    "    cond_fs_df = extractSelectedConceptID(cond_df, cond_vars_df.concept_id.unique())\n",
    "\n",
    "    all_domain_df = pd.concat([meas_fs_df, drug_fs_df, proc_fs_df, cond_fs_df], axis=0, ignore_index=True)\n",
    "\n",
    "    pivot_data = pivotting(all_domain_df)\n",
    "\n",
    "    drop_cols = []\n",
    "    for col in pivot_data.columns:\n",
    "        if (len(pivot_data[pivot_data[col].notnull()])/len(pivot_data[col]) < 0.3):\n",
    "            drop_cols.append(col)\n",
    "    print(drop_cols)\n",
    "    \n",
    "    pivot_data = pivot_data.drop(drop_cols, axis='columns')\n",
    "\n",
    "    domain_ids={}\n",
    "    domain_ids['meas'] = np.setdiff1d(meas_fs_df.concept_id.unique(), drop_cols)\n",
    "    domain_ids['drug'] = np.setdiff1d(drug_fs_df.concept_id.unique(), drop_cols)\n",
    "    domain_ids['proc'] = np.setdiff1d(proc_fs_df.concept_id.unique(), drop_cols)\n",
    "    domain_ids['cond'] = np.setdiff1d(cond_fs_df.concept_id.unique(), drop_cols)\n",
    "\n",
    "    # -------- time series data ---------\n",
    "    interpolate_df = day_sequencing_interpolate(pivot_data, domain_ids, OBP=params[\"windowsize\"])\n",
    "\n",
    "    label_1 = interpolate_df[interpolate_df['label']==1]\n",
    "    label_0 = interpolate_df[interpolate_df['label']==0]\n",
    "\n",
    "    rolled_label1_d = shift_rolling_window(label_1, OBP=params[\"windowsize\"], nShift=params[\"shift\"], uid_index=1)\n",
    "    rolled_label0_d = label_0_fitting(label_0, OBP=params[\"windowsize\"], nShift=params[\"shift\"], uid_index=(rolled_label1_d.unique_id.max()+1))\n",
    "\n",
    "    # label 0 + label 1\n",
    "    concat_df = pd.concat([rolled_label1_d, rolled_label0_d], sort=False)\n",
    "    concat_df = concat_df.sort_values(['unique_id', 'concept_date'])\n",
    "    # -------- time series data ---------\n",
    "\n",
    "    concept_dict = dict(zip(all_domain_df.concept_id, all_domain_df.concept_name))\n",
    "    concat_4w_df = resampling_4w(concat_df)\n",
    "    draw_4w_df = concat_4w_df.copy()\n",
    "    draw_4w_df['sequence'] = draw_4w_df.groupby('unique_id').cumcount()+1\n",
    "    save_all_features(output_result_dir, draw_4w_df, concept_dict)\n",
    "\n",
    "    # Normalization (Min/Max Scalar)\n",
    "    concat_df = normalization(concat_df)\n",
    "    concat_df = concat_df.dropna(axis=1)\n",
    "    concat_4w_df = normalization(concat_4w_df)\n",
    "    concat_4w_df = concat_4w_df.dropna(axis=1)\n",
    "\n",
    "    # columns name : concept_id > concept_name\n",
    "    concat_df = concat_df.rename(concept_dict, axis='columns')\n",
    "    concat_4w_df = concat_4w_df.rename(concept_dict, axis='columns')\n",
    "\n",
    "    # Save File\n",
    "    concat_df.to_csv('{}/{}.txt'.format(output_data_dir, outcome_name), index=False, float_format='%g')\n",
    "    concat_4w_df.to_csv('{}/{}_4w.txt'.format(output_data_dir, outcome_name), index=False, float_format='%g')\n",
    "\n",
    "    output={}\n",
    "    output['meas_whole_var'] = len(meas_df.concept_id.unique())\n",
    "    output['drug_whole_var'] = len(drug_df.concept_id.unique())\n",
    "    output['proc_whole_var'] = len(proc_df.concept_id.unique())\n",
    "    output['cond_whole_var'] = len(cond_df.concept_id.unique())\n",
    "    output['meas_selected_var'] = len(domain_ids['meas'])\n",
    "    output['drug_selected_var'] = len(domain_ids['drug'])\n",
    "    output['proc_selected_var'] = len(domain_ids['proc'])\n",
    "    output['cond_selected_var'] = len(domain_ids['cond'])\n",
    "    output['nPatient_label1'] = len(concat_df[concat_df[\"label\"] == 1])\n",
    "    output['nPatient_label0'] = len(concat_df[concat_df[\"label\"] == 0])\n",
    "\n",
    "    # print\n",
    "    print(output['meas_whole_var'], output['meas_selected_var'])\n",
    "    print(output['drug_whole_var'], output['drug_selected_var'])\n",
    "    print(output['proc_whole_var'], output['proc_selected_var'])\n",
    "    print(output['cond_whole_var'], output['cond_selected_var'])\n",
    "\n",
    "    out = open('{}/output.txt'.format(output_result_dir),'a')\n",
    "\n",
    "    out.write(str(outcome_name) + '///' )\n",
    "    out.write(str(output['meas_whole_var']) + '///')\n",
    "    out.write(str(output['meas_selected_var']) + '///')\n",
    "    out.write(str(output['drug_whole_var']) + '///')\n",
    "    out.write(str(output['drug_selected_var']) + '///')\n",
    "    out.write(str(output['proc_whole_var']) + '///')\n",
    "    out.write(str(output['proc_selected_var']) + '///')\n",
    "    out.write(str(output['cond_whole_var']) + '///')\n",
    "    out.write(str(output['cond_selected_var']) + '///')\n",
    "    out.write(str(output['nPatient_label1']) + '///')\n",
    "    out.write(str(output['nPatient_label0']) + '\\n')\n",
    "    out.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\"\"\"\n",
    "    For all drugs, perform the above tasks.\n",
    "\"\"\"\n",
    "for outcome_name in tqdm(cfg['drug'].keys()) :\n",
    "    try :\n",
    "        log.debug('drug : {}'.format(outcome_name))\n",
    "        runTask(outcome_name)\n",
    "    except :\n",
    "        traceback.print_exc()\n",
    "        log.error(traceback.format_exc())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit ('3.9.12')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fcbb2fcbd39d2032f42f25d14b9b7513f85054c4719b23117903ced3da54211e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
