{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. preprocessing for XGBoost (baseline)\n",
    "  * 1) feature selection\n",
    "    2) convert to baseline data\n",
    "    3) normalization \n",
    "\n",
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\"\"\"\n",
    "    1) import package\n",
    "\"\"\"\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pathlib\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import traceback\n",
    "from tqdm import tqdm\n",
    "from datetime import timedelta\n",
    "from _utils.preprocessing_xgboost import *\n",
    "from _utils.customlogger import customlogger as CL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\"\"\"\n",
    "    2) loading config\n",
    "\"\"\"\n",
    "with open('./../{}'.format(\"config.json\")) as file:\n",
    "    cfg = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\"\"\"\n",
    "    3) load information \n",
    "\"\"\"\n",
    "current_dir = pathlib.Path.cwd()\n",
    "parent_dir = current_dir.parent\n",
    "current_date = cfg[\"working_date\"]\n",
    "curr_file_name = os.path.splitext(os.path.basename(os.path.abspath('')))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\"\"\"\n",
    "    4) create Logger\n",
    "\"\"\"\n",
    "log = CL(\"custom_logger\")\n",
    "pathlib.Path.mkdir(pathlib.Path('{}/_log/'.format(parent_dir)), mode=0o777, parents=True, exist_ok=True)\n",
    "log = log.create_logger(file_name=\"../_log/{}.log\".format(curr_file_name), mode=\"a\", level=\"DEBUG\")  \n",
    "log.debug('start {}'.format(curr_file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runTask(outcome_name):\n",
    "    # In[ ]:\n",
    "    \"\"\"\n",
    "        (1) set path & make directory\n",
    "    \"\"\"\n",
    "    importsql_data_dir  = pathlib.Path('{}/data/{}/importsql/{}/'.format(parent_dir, current_date, outcome_name))\n",
    "    output_data_dir     = pathlib.Path('{}/data/{}/preprocess_xgboost/{}/'.format(parent_dir, current_date, outcome_name))\n",
    "    output_result_dir   = pathlib.Path('{}/result/{}/preprocess_xgboost/{}/'.format(parent_dir, current_date, outcome_name))\n",
    "    pathlib.Path.mkdir(output_data_dir, mode=0o777, parents=True, exist_ok=True)\n",
    "    pathlib.Path.mkdir(output_result_dir, mode=0o777, parents=True, exist_ok=True)\n",
    "    \n",
    "    # In[ ]:\n",
    "    \"\"\"\n",
    "        (2) Skip if there is no patient data\n",
    "    \"\"\"\n",
    "    if not pathlib.Path.exists(importsql_data_dir.joinpath('all_domain_df.txt')):\n",
    "        log.debug(f\"{outcome_name} data frame is empty\")\n",
    "        return\n",
    "    \n",
    "    # In[ ]:\n",
    "    \"\"\"\n",
    "        (3) read data frame\n",
    "    \"\"\"\n",
    "    all_domain_df = pd.read_csv(importsql_data_dir.joinpath('all_domain_df.txt'), low_memory=False)\n",
    "    print(all_domain_df.concept_domain.value_counts())\n",
    "    print('label 1 : ', len(all_domain_df[all_domain_df['label']==1].person_id.unique()))\n",
    "    print('label 0 : ', len(all_domain_df[all_domain_df['label']==0].person_id.unique()))\n",
    "    nCase = all_domain_df.loc[all_domain_df['label'] == 1].person_id.nunique()\n",
    "    if nCase < 20:\n",
    "        log.debug(f\"{outcome_name} case is less than 20\")\n",
    "        return\n",
    "\n",
    "    # In[ ]:\n",
    "    \"\"\"\n",
    "        (4) use only necessary columns\n",
    "    \"\"\"\n",
    "    common_cols = ['person_id', 'age', 'sex', 'cohort_start_date', 'first_abnormal_date', 'concept_date', 'concept_id', 'concept_name', 'concept_value', 'concept_domain', 'label']\n",
    "    all_domain_df = all_domain_df[common_cols]\n",
    "\n",
    "    # In[ ]:\n",
    "    \"\"\"\n",
    "        (5) Remove feature used in outcome define\n",
    "    \"\"\"\n",
    "    drug_name = outcome_name\n",
    "    drug_concept_ids_excluded = map(int,cfg['drug'][drug_name]['@drug_concept_set'].split(','))\n",
    "    all_domain_df = all_domain_df.loc[~all_domain_df.concept_id.isin(drug_concept_ids_excluded)]\n",
    "    meas_concept_ids_excluded = map(int,[cfg['meas'][meas_name]['@meas_concept_id'] for meas_name in cfg['meas']])\n",
    "    all_domain_df = all_domain_df.loc[~all_domain_df.concept_id.isin(meas_concept_ids_excluded)]\n",
    "\n",
    "    meas_df = all_domain_df.loc[all_domain_df.concept_domain=='meas'].reset_index(drop=True)\n",
    "    drug_df = all_domain_df.loc[all_domain_df.concept_domain=='drug'].reset_index(drop=True)\n",
    "    proc_df = all_domain_df.loc[all_domain_df.concept_domain=='proc'].reset_index(drop=True)\n",
    "    cond_df = all_domain_df.loc[all_domain_df.concept_domain=='cond'].reset_index(drop=True)\n",
    "\n",
    "    # @variable selection\n",
    "    meas_vars_df = variant_selection_paired_t_test(meas_df)\n",
    "    drug_vars_df = variant_selection_mcnemar(drug_df)\n",
    "    proc_vars_df = variant_selection_mcnemar(proc_df)\n",
    "    cond_vars_df = variant_selection_mcnemar(cond_df)\n",
    "\n",
    "    # @variable selection\n",
    "    meas_vars_df = meas_vars_df.sort_values(by='pvalue', ascending=True).reset_index(drop=True)\n",
    "    drug_vars_df = drug_vars_df.sort_values(by='pvalue', ascending=True).reset_index(drop=True)\n",
    "    cond_vars_df = cond_vars_df.sort_values(by='pvalue', ascending=True).reset_index(drop=True)\n",
    "    proc_vars_df = proc_vars_df.sort_values(by='pvalue', ascending=True).reset_index(drop=True)\n",
    "\n",
    "    log.info(\"[nVar] m : {} d : {} p : {}  c: {}\".format(len(meas_vars_df), len(drug_vars_df), len(proc_vars_df), len(cond_vars_df)))\n",
    "\n",
    "    meas_vars_df['concept_domain'] = 'meas'\n",
    "    drug_vars_df['concept_domain'] = 'drug'\n",
    "    proc_vars_df['concept_domain'] = 'proc'\n",
    "    cond_vars_df['concept_domain'] = 'cond'\n",
    "\n",
    "    all_domain_vars_df = pd.concat([meas_vars_df, drug_vars_df, cond_vars_df, proc_vars_df], axis=0, ignore_index=True)\n",
    "    # @variable selection (save)\n",
    "    all_domain_vars_df.to_csv('{}/{}_feature.csv'.format(output_result_dir, outcome_name), header=True, index=True)\n",
    "\n",
    "    # @Extract only selected concepts from data frame\n",
    "    def extractSelectedConceptID(domain_df, concept_id_list):\n",
    "        extract_domain_df = domain_df[domain_df['concept_id'].isin(concept_id_list)]\n",
    "        print(len(concept_id_list), len(domain_df), len(extract_domain_df))\n",
    "        return extract_domain_df\n",
    "\n",
    "    meas_df2 = extractSelectedConceptID(meas_df, meas_vars_df.concept_id.unique())\n",
    "    drug_df2 = extractSelectedConceptID(drug_df, drug_vars_df.concept_id.unique())\n",
    "    proc_df2 = extractSelectedConceptID(proc_df, proc_vars_df.concept_id.unique())\n",
    "    cond_df2 = extractSelectedConceptID(cond_df, cond_vars_df.concept_id.unique())\n",
    "\n",
    "    all_domain_df = pd.concat([meas_df2, drug_df2, proc_df2, cond_df2], axis=0, ignore_index=True)\n",
    "\n",
    "    # In[]:\n",
    "    pivot_data = pivotting(all_domain_df)\n",
    "\n",
    "    drop_cols = []\n",
    "    for col in pivot_data.columns:\n",
    "        if (len(pivot_data[pivot_data[col].notnull()])/len(pivot_data[col]) < 0.3):\n",
    "            drop_cols.append(col)\n",
    "\n",
    "    pivot_data = pivot_data.drop(drop_cols, axis='columns')\n",
    "\n",
    "    pivot_data = pivot_data.query(\"concept_date <= cohort_start_date\")\n",
    "    pivot_data = pivot_data.sort_values(by=[\"person_id\", \"concept_date\"], axis=0, ascending=[True, False]).reset_index(drop=True)\n",
    "    pivot_data = pivot_data.drop_duplicates(subset=['person_id'], keep = 'first')\n",
    "    pivot_data = pivot_data.fillna(0)\n",
    "\n",
    "    domain_ids={}\n",
    "    domain_ids['meas'] = np.setdiff1d(meas_df2.concept_id.unique(), drop_cols)\n",
    "    domain_ids['drug'] = np.setdiff1d(drug_df2.concept_id.unique(), drop_cols)\n",
    "    domain_ids['proc'] = np.setdiff1d(proc_df2.concept_id.unique(), drop_cols)\n",
    "    domain_ids['cond'] = np.setdiff1d(cond_df2.concept_id.unique(), drop_cols)\n",
    "    print(len(domain_ids['meas']), len(domain_ids['drug']), len(domain_ids['proc']), len(domain_ids['cond']))\n",
    "\n",
    "    # Normalization (Min/Max Scalar)\n",
    "    concat_df = normalization(pivot_data)\n",
    "    concat_df = concat_df.dropna(axis=1)\n",
    "\n",
    "    # columns name : concept_id > concept_name\n",
    "    concept_dict = dict(zip(all_domain_df.concept_id, all_domain_df.concept_name))\n",
    "    concat_df = concat_df.rename(concept_dict, axis='columns')\n",
    "\n",
    "    # Save File\n",
    "    concat_df.to_csv('{}/{}.txt'.format(output_data_dir, outcome_name), index=False, float_format='%g')\n",
    "\n",
    "    output={}\n",
    "    output['meas_whole_var'] = len(meas_df.concept_id.unique())\n",
    "    output['drug_whole_var'] = len(drug_df.concept_id.unique())\n",
    "    output['proc_whole_var'] = len(proc_df.concept_id.unique())\n",
    "    output['cond_whole_var'] = len(cond_df.concept_id.unique())\n",
    "    output['meas_selected_var'] = len(domain_ids['meas'])\n",
    "    output['drug_selected_var'] = len(domain_ids['drug'])\n",
    "    output['proc_selected_var'] = len(domain_ids['proc'])\n",
    "    output['cond_selected_var'] = len(domain_ids['cond'])\n",
    "    output['nPatient_label1'] = len(concat_df[concat_df[\"label\"] == 1])\n",
    "    output['nPatient_label0'] = len(concat_df[concat_df[\"label\"] == 0])\n",
    "\n",
    "    # print\n",
    "    print(output['meas_whole_var'], output['meas_selected_var'])\n",
    "    print(output['drug_whole_var'], output['drug_selected_var'])\n",
    "    print(output['proc_whole_var'], output['proc_selected_var'])\n",
    "    print(output['cond_whole_var'], output['cond_selected_var'])\n",
    "\n",
    "    out = open('{}/output.txt'.format(output_result_dir),'a')\n",
    "\n",
    "    out.write(str(outcome_name) + '///' )\n",
    "    out.write(str(output['meas_whole_var']) + '///')\n",
    "    out.write(str(output['meas_selected_var']) + '///')\n",
    "    out.write(str(output['drug_whole_var']) + '///')\n",
    "    out.write(str(output['drug_selected_var']) + '///')\n",
    "    out.write(str(output['proc_whole_var']) + '///')\n",
    "    out.write(str(output['proc_selected_var']) + '///')\n",
    "    out.write(str(output['cond_whole_var']) + '///')\n",
    "    out.write(str(output['cond_selected_var']) + '///')\n",
    "    out.write(str(output['nPatient_label1']) + '///')\n",
    "    out.write(str(output['nPatient_label0']) + '\\n')\n",
    "    out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\"\"\"\n",
    "    For all drugs, perform the above tasks.\n",
    "\"\"\"\n",
    "for outcome_name in tqdm(cfg['drug'].keys()) :\n",
    "    try :\n",
    "        log.debug('drug : {}'.format(outcome_name))\n",
    "        runTask(outcome_name)\n",
    "    except :\n",
    "        traceback.print_exc()\n",
    "        log.error(traceback.format_exc())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit ('3.9.12')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fcbb2fcbd39d2032f42f25d14b9b7513f85054c4719b23117903ced3da54211e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
