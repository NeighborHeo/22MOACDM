{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Selection of Predictor variable\n",
    "  * Select predictor variables using various variable selection methods\n",
    "\n",
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\"\"\"\n",
    "    1) import package\n",
    "\"\"\"\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pathlib\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import traceback\n",
    "from tqdm import tqdm\n",
    "from datetime import timedelta\n",
    "from _utils.feature_selection import *\n",
    "from _utils.customlogger import customlogger as CL\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\"\"\"\n",
    "    2) loading config\n",
    "\"\"\"\n",
    "current_dir = pathlib.Path.cwd()\n",
    "parent_dir = current_dir.parent\n",
    "with open(parent_dir.joinpath(\"config.json\")) as file:\n",
    "    cfg = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\"\"\"\n",
    "    3) load information \n",
    "\"\"\"\n",
    "current_date = cfg[\"working_date\"]\n",
    "curr_file_name = os.path.splitext(os.path.basename(os.path.abspath('')))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\"\"\"\n",
    "    4) create Logger\n",
    "\"\"\"\n",
    "log = CL(\"custom_logger\")\n",
    "pathlib.Path.mkdir(pathlib.Path('{}/_log/'.format(parent_dir)), mode=0o777, parents=True, exist_ok=True)\n",
    "log = log.create_logger(file_name=\"../_log/{}.log\".format(curr_file_name), mode=\"a\", level=\"DEBUG\")  \n",
    "log.debug('start {}'.format(curr_file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "def runTask(outcome_name):\n",
    "    # In[ ]:\n",
    "    \"\"\"\n",
    "        (1) set path & make directory\n",
    "    \"\"\"\n",
    "    importsql_data_dir   = pathlib.Path('{}/data/{}/importsql/{}/'.format(parent_dir, current_date, outcome_name))\n",
    "    output_data_dir      = pathlib.Path('{}/data/{}/feature_selection/{}/'.format(parent_dir, current_date, outcome_name))\n",
    "    output_result_dir    = pathlib.Path('{}/result/{}/feature_selection/{}/'.format(parent_dir, current_date, outcome_name))\n",
    "    pathlib.Path.mkdir(output_data_dir, mode=0o777, parents=True, exist_ok=True)\n",
    "    pathlib.Path.mkdir(output_result_dir, mode=0o777, parents=True, exist_ok=True)\n",
    "\n",
    "    # In[ ]:\n",
    "    \"\"\"\n",
    "        (2) read data\n",
    "    \"\"\"\n",
    "    if not pathlib.Path.exists(importsql_data_dir.joinpath('all_domain_df.txt')):\n",
    "        log.debug(f\"{outcome_name} data frame is empty\")\n",
    "        return\n",
    "    \n",
    "    all_domain_df = pd.read_csv(importsql_data_dir.joinpath('all_domain_df.txt'), low_memory=False)\n",
    "    nCase = all_domain_df.loc[all_domain_df['label'] == 1].person_id.nunique()\n",
    "    if nCase < 20:\n",
    "        log.debug(f\"{outcome_name} case is less than 20\")\n",
    "        return\n",
    "\n",
    "    # In[ ]:\n",
    "    \"\"\"\n",
    "        (3) use only necessary columns\n",
    "    \"\"\"\n",
    "    common_cols = ['person_id', 'age', 'sex', 'cohort_start_date', 'first_abnormal_date', 'concept_date', 'concept_id', 'concept_name', 'concept_value', 'concept_domain', 'label']\n",
    "    all_domain_df = all_domain_df[common_cols]\n",
    "    \n",
    "    # In[ ]:\n",
    "    \"\"\"\n",
    "        (4) Remove feature used in outcome define\n",
    "    \"\"\"\n",
    "    drug_name = outcome_name\n",
    "    drug_concept_ids_excluded = map(int,cfg['drug'][drug_name]['@drug_concept_set'].split(','))\n",
    "    all_domain_df = all_domain_df.loc[~all_domain_df.concept_id.isin(drug_concept_ids_excluded)]\n",
    "    meas_concept_ids_excluded = map(int,[cfg['meas'][meas_name]['@meas_concept_id'] for meas_name in cfg['meas']])\n",
    "    all_domain_df = all_domain_df.loc[~all_domain_df.concept_id.isin(meas_concept_ids_excluded)]\n",
    "    \n",
    "    all_domain_df['cohort_start_date'] = pd.to_datetime(all_domain_df['cohort_start_date'], infer_datetime_format=True)\n",
    "    all_domain_df['first_abnormal_date'] = pd.to_datetime(all_domain_df['first_abnormal_date'], infer_datetime_format=True)\n",
    "    all_domain_df['concept_date'] = pd.to_datetime(all_domain_df['concept_date'], infer_datetime_format=True)\n",
    "\n",
    "    # In[ ]:\n",
    "    \"\"\"\n",
    "        (5) Check the average duration of occurrence until side effects\n",
    "    \"\"\"\n",
    "    ndays = average_duration_of_adverse_events(all_domain_df)\n",
    "    log.debug('average_duration_of_adverse_events : {}'.format(ndays))\n",
    "\n",
    "    # In[ ]:\n",
    "    \"\"\"\n",
    "        (6) make baseline data\n",
    "    \"\"\"\n",
    "    all_domain_pivot_df = make_pivot(all_domain_df)\n",
    "    all_domain_baseline_df = all_domain_df.query('cohort_start_date >= concept_date')\n",
    "    all_domain_pivot_baseline_df = make_pivot(all_domain_baseline_df)\n",
    "\n",
    "    summary_df = resumetable(all_domain_pivot_df)\n",
    "    write_file_method(summary_df, output_result_dir, outcome_name, 'summary')\n",
    "\n",
    "    concept_id_name_dict = dict(zip(all_domain_df.concept_id, all_domain_df.concept_name))\n",
    "    concept_id_domain_dict = dict(zip(all_domain_df.concept_id, all_domain_df.concept_domain))\n",
    "\n",
    "    feature_selection_method_df_dict = {}\n",
    "    \n",
    "    \n",
    "    # In[ ]:\n",
    "    \"\"\"\n",
    "        (7) Feature_Selection Method 1 : statistics method\n",
    "    \"\"\"\n",
    "    meas_concept_ids = list(all_domain_df.loc[all_domain_df.concept_domain=='meas'].concept_id.values)\n",
    "    drug_concept_ids = list(all_domain_df.loc[all_domain_df.concept_domain=='drug'].concept_id.values)\n",
    "    proc_concept_ids = list(all_domain_df.loc[all_domain_df.concept_domain=='proc'].concept_id.values)\n",
    "    cond_concept_ids = list(all_domain_df.loc[all_domain_df.concept_domain=='cond'].concept_id.values)\n",
    "\n",
    "    selected_features_with_t_test_df = getPairedTTest(all_domain_pivot_baseline_df, all_domain_pivot_df, meas_concept_ids)\n",
    "    selected_features_with_mcnemar_df = getMcnemarTest(all_domain_pivot_baseline_df, all_domain_pivot_df, drug_concept_ids + cond_concept_ids + proc_concept_ids)\n",
    "\n",
    "    selected_features_df = pd.concat([selected_features_with_t_test_df, selected_features_with_mcnemar_df], axis=0)\n",
    "    if not selected_features_df.empty:\n",
    "        selected_features_df.concept_id = selected_features_df.concept_id.astype(np.object)\n",
    "    selected_features_df = add_column_concept_name(selected_features_df, concept_id_name_dict)\n",
    "    selected_features_df = add_column_concept_domain(selected_features_df, concept_id_domain_dict)\n",
    "    write_file_method(selected_features_df, output_result_dir, outcome_name, 'statistics')\n",
    "    feature_selection_method_df_dict['statistics'] = selected_features_df\n",
    "\n",
    "    len(all_domain_df.concept_id.unique()), len(all_domain_baseline_df.concept_id.unique())\n",
    "\n",
    "    # In[ ]:\n",
    "    \"\"\"\n",
    "        (8) imputation missing data\n",
    "    \"\"\"\n",
    "    all_domain_pivot_df = impute_conditional_data(all_domain_pivot_df, meas_concept_ids)\n",
    "    all_domain_pivot_df = impute_binary_data(all_domain_pivot_df, drug_concept_ids + proc_concept_ids + cond_concept_ids)\n",
    "\n",
    "    meas_concept_ids = list(all_domain_baseline_df.loc[all_domain_baseline_df.concept_domain=='meas'].concept_id.values)\n",
    "    drug_concept_ids = list(all_domain_baseline_df.loc[all_domain_baseline_df.concept_domain=='drug'].concept_id.values)\n",
    "    proc_concept_ids = list(all_domain_baseline_df.loc[all_domain_baseline_df.concept_domain=='proc'].concept_id.values)\n",
    "    cond_concept_ids = list(all_domain_baseline_df.loc[all_domain_baseline_df.concept_domain=='cond'].concept_id.values)\n",
    "\n",
    "    all_domain_pivot_baseline_df = impute_conditional_data(all_domain_pivot_baseline_df, meas_concept_ids)\n",
    "    all_domain_pivot_baseline_df = impute_binary_data(all_domain_pivot_baseline_df, drug_concept_ids + proc_concept_ids + cond_concept_ids)\n",
    "\n",
    "    X_total, y_total, cols = getxydata(all_domain_pivot_df)\n",
    "    X_total = normalization_minmax(X_total)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_total, y_total, test_size=0.3, random_state=1, stratify=y_total) \n",
    "\n",
    "    # check for nan / infinite value \n",
    "    np.argwhere(np.isnan(X_train)), np.argwhere(np.isinf(X_train))\n",
    "\n",
    "    # In[ ]:\n",
    "    \"\"\"\n",
    "        (9) Feature_Selection Method 2 : VarianceThreshold\n",
    "    \"\"\"\n",
    "    selector = VarianceThreshold(1e-3)\n",
    "    X_train_sel = selector.fit_transform(X_train)\n",
    "    X_test_sel = selector.transform(X_test)\n",
    "    print(X_train.shape, X_train_sel.shape)\n",
    "    selected_features = selector.get_feature_names_out(cols)\n",
    "    selected_features_df = make_concepts_df(selected_features, concept_id_name_dict, concept_id_domain_dict)\n",
    "    write_file_method(selected_features_df, output_result_dir, outcome_name, 'VT')\n",
    "    feature_selection_method_df_dict['VT'] = selected_features_df\n",
    "\n",
    "    # In[ ]:\n",
    "    \"\"\"\n",
    "        (10) Feature_Selection Method 3 : SelectPercentile\n",
    "    \"\"\"\n",
    "    selector = SelectPercentile(chi2, percentile=3) # now select features based on top 10 percentile\n",
    "    X_train_sel = selector.fit_transform(X_train, y_train)\n",
    "    X_test_sel = selector.transform(X_test)\n",
    "    print(X_train.shape, X_train_sel.shape)\n",
    "    selected_features = selector.get_feature_names_out(cols)\n",
    "    selected_features_df = make_concepts_df(selected_features, concept_id_name_dict, concept_id_domain_dict)\n",
    "    write_file_method(selected_features_df, output_result_dir, outcome_name, 'percentile')\n",
    "    feature_selection_method_df_dict['percentile'] = selected_features_df\n",
    "\n",
    "    # In[ ]:\n",
    "    \"\"\"\n",
    "        (11) Feature_Selection Method 4 : SelectPercentile\n",
    "    \"\"\"\n",
    "    selector = SelectKBest(score_func=chi2, k=50)\n",
    "    X_train_sel = selector.fit_transform(X_train, y_train)\n",
    "    X_test_sel = selector.transform(X_test)\n",
    "    print(X_train.shape, X_train_sel.shape)\n",
    "    selected_features = selector.get_feature_names_out(cols)\n",
    "    selected_features_df = make_concepts_df(selected_features, concept_id_name_dict, concept_id_domain_dict)\n",
    "    write_file_method(selected_features_df, output_result_dir, outcome_name, 'KBest')\n",
    "    feature_selection_method_df_dict['KBest'] = selected_features_df\n",
    "\n",
    "    # In[ ]:\n",
    "    \"\"\"\n",
    "        (12) Feature_Selection Method 5 : ExtraTreesClassifier\n",
    "    \"\"\"\n",
    "    treebasedclf = ExtraTreesClassifier(n_estimators=50)\n",
    "    treebasedclf = treebasedclf.fit(X_train, y_train)\n",
    "    model = SelectFromModel(treebasedclf, prefit=True)\n",
    "    X_train_sel = model.transform(X_train)\n",
    "    print(X_train.shape, X_train_sel.shape)\n",
    "    selected_features = model.get_feature_names_out(cols)\n",
    "    selected_features_df = make_concepts_df(selected_features, concept_id_name_dict, concept_id_domain_dict)\n",
    "    write_file_method(selected_features_df, output_result_dir, outcome_name, 'ExtraTrees')\n",
    "    feature_selection_method_df_dict['ExtraTrees'] = selected_features_df\n",
    "\n",
    "    # In[ ]:\n",
    "    \"\"\"\n",
    "        (13) Feature_Selection Method 6 : Lasso (1) > alpha = 0.1\n",
    "    \"\"\"\n",
    "    lasso = Lasso(alpha=0.1)\n",
    "    lasso.fit(X_train, y_train)\n",
    "    # print(lasso.coef_)\n",
    "    importance = np.abs(lasso.coef_)\n",
    "    selected_features = np.array(cols)[importance > 0]\n",
    "    selected_features_df = make_concepts_df(selected_features, concept_id_name_dict, concept_id_domain_dict)\n",
    "\n",
    "    write_file_method(selected_features_df, output_result_dir, outcome_name, 'lasso_0_1')\n",
    "    feature_selection_method_df_dict['lasso_0_1'] = selected_features_df\n",
    "\n",
    "    # In[ ]:\n",
    "    \"\"\"\n",
    "        (14) Feature_Selection Method 7 : mutual_info_classif\n",
    "    \"\"\"\n",
    "    importances = mutual_info_classif(X_total, y_total, discrete_features='auto')\n",
    "    threshold = 0.001\n",
    "    selected_features = np.array(cols)[importance > threshold]\n",
    "    selected_features_df = make_concepts_df(selected_features, concept_id_name_dict, concept_id_domain_dict)\n",
    "    write_file_method(selected_features_df, output_result_dir, outcome_name, 'mutual')\n",
    "    feature_selection_method_df_dict['mutual'] = selected_features_df\n",
    "\n",
    "    # In[ ]:\n",
    "    \"\"\"\n",
    "        (15) all methods concatenate\n",
    "    \"\"\"\n",
    "    concat_df = concat_all_methods(feature_selection_method_df_dict)\n",
    "    write_file_method(concat_df, output_result_dir, outcome_name, 'all_methods')\n",
    "    summary_concat_df = merge_summary_table_df(summary_df, concat_df)\n",
    "    write_file_method(summary_concat_df, output_result_dir, outcome_name, 'total')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\"\"\"\n",
    "    For all drugs, perform the above tasks.\n",
    "\"\"\"\n",
    "for outcome_name in tqdm(cfg['drug'].keys()) :\n",
    "    try :\n",
    "        log.debug('drug : {}'.format(outcome_name))\n",
    "        runTask(outcome_name)\n",
    "    except :\n",
    "        traceback.print_exc()\n",
    "        log.error(traceback.format_exc())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "65a9df8dabcfad470e190f31aab646891f837e6d422cdbd7188428f094f05b09"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
