{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. IMV LSTM Attention (Multivariate Attention)\n",
    "  1) Create a time series prediction model using preprocessed data. \n",
    "  2) evaluate the results\n",
    "  * reference : Guo, Tian, Tao Lin, and Nino Antulov-Fantulin. \"Exploring interpretable lstm neural networks over multi-variable data.\" International conference on machine learning. PMLR, 2019.\n",
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\"\"\"\n",
    "    1) import package\n",
    "\"\"\"\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pathlib\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "\n",
    "import traceback\n",
    "from tqdm import tqdm\n",
    "import textwrap\n",
    "\n",
    "from _utils.Auto_lstm_attention import *\n",
    "from _utils.model_estimation import *\n",
    "from _utils.customlogger import customlogger as CL\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from _utils.imv_lstm_model import IMVFullLSTM\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "# for linux\n",
    "os.environ[\"HDF5_USE_FILE_LOCKING\"] = \"FALSE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\"\"\"\n",
    "    2) set GPU or CPU Device\n",
    "\"\"\"\n",
    "# If using GPU set to 0, Otherwise, using CPU set to -1 (If the value is changed, a restart is required.)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\" \n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\"\"\"\n",
    "    2) loading config\n",
    "\"\"\"\n",
    "current_dir = pathlib.Path.cwd()\n",
    "parent_dir = current_dir.parent\n",
    "with open(parent_dir.joinpath(\"config.json\")) as file:\n",
    "    cfg = json.load(file)\n",
    "with open(parent_dir.joinpath(\"config_params.json\")) as file:\n",
    "    params = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\"\"\"\n",
    "    3) load information \n",
    "\"\"\"\n",
    "current_date = cfg[\"working_date\"]\n",
    "curr_file_name = os.path.splitext(os.path.basename(os.path.abspath('')))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\"\"\"\n",
    "    4) create Logger\n",
    "\"\"\"\n",
    "log = CL(\"custom_logger\")\n",
    "pathlib.Path.mkdir(pathlib.Path('{}/_log/'.format(parent_dir)), mode=0o777, parents=True, exist_ok=True)\n",
    "log = log.create_logger(file_name=\"../_log/{}.log\".format(curr_file_name), mode=\"a\", level=\"DEBUG\")  \n",
    "log.debug('start {}'.format(curr_file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\"\"\"\n",
    "    4) user functions definition \n",
    "\"\"\"\n",
    "def get_time_stamp(df):\n",
    "    return int(len(df)/len(df.unique_id.unique()))\n",
    "\n",
    "def split_x_y_data(df, n_timestamp):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    y_data = df['label'].T.reset_index(drop=True) #df['label'].T.drop_duplicates().T.reset_index(drop=True)\n",
    "    y_data = np.array(y_data)\n",
    "    y_data = y_data[0:len(y_data):n_timestamp].reshape(-1, 1).astype(int)\n",
    "    #print(len(y_data), file=_logfile_)\n",
    "\n",
    "    X_df = df.drop('label', axis=1)\n",
    "\n",
    "    # 2-d data to 3-d data\n",
    "    X_data = np.array(X_df)\n",
    "    X_data = X_data.reshape(-1, n_timestamp, X_data.shape[1]) # -1(sample), timestamp, column\n",
    "    #X_data.shape, y_data.shape\n",
    "\n",
    "    # get Column data\n",
    "    new_col = X_df.columns\n",
    "    print(X_data.shape, y_data.shape, len(new_col))\n",
    "    return X_data, y_data, new_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runTask(outcome_name):\n",
    "    # In[ ]:\n",
    "    \"\"\"\n",
    "        (1) set path & make directory\n",
    "    \"\"\"\n",
    "    ps_data_dir         = pathlib.Path('{}/data/{}/preprocess_lstm/{}/'.format(parent_dir, current_date, outcome_name))\n",
    "    output_data_dir     = pathlib.Path('{}/data/{}/imv_lstm_attention/{}/'.format(parent_dir, current_date, outcome_name))\n",
    "    output_result_dir   = pathlib.Path('{}/result/{}/imv_lstm_attention/{}/'.format(parent_dir, current_date, outcome_name))\n",
    "    pathlib.Path.mkdir(output_data_dir, mode=0o777, parents=True, exist_ok=True)\n",
    "    pathlib.Path.mkdir(output_result_dir, mode=0o777, parents=True, exist_ok=True)\n",
    "\n",
    "    # In[ ]:\n",
    "    \"\"\"\n",
    "        (2) load data (preprocessed)\n",
    "    \"\"\"\n",
    "    filename = \"{}_4w.txt\".format(outcome_name)\n",
    "    filepath = ps_data_dir.joinpath(filename)\n",
    "    if not filepath.exists():\n",
    "        log.debug(\"file not exist: {}\".format(filepath))\n",
    "        return\n",
    "\n",
    "    concat_df = pd.read_csv(ps_data_dir.joinpath(filename), index_col=False)\n",
    "    \n",
    "    if concat_df.empty:\n",
    "        print(outcome_name, \" is empty\")\n",
    "        return\n",
    "\n",
    "    nCase = concat_df.loc[concat_df['label'] == 1].person_id.nunique()\n",
    "    if nCase < 20:\n",
    "        log.debug(f\"{outcome_name} case is less than 20\")\n",
    "        return\n",
    "\n",
    "    # In[ ]:\n",
    "    \"\"\"\n",
    "        (3) \n",
    "    \"\"\"\n",
    "    n_timestamp = get_time_stamp(concat_df) \n",
    "\n",
    "    # In[ ]:\n",
    "    \"\"\"\n",
    "        (4) split data (train : valid : test = 0.6 : 0.2 : 0.2)\n",
    "    \"\"\"\n",
    "    # #### Split ignore person_id #####\n",
    "    concat_df = concat_df.drop(['person_id', 'unique_id', 'cohort_start_date', 'concept_date', 'first_abnormal_date'], axis=1)\n",
    "\n",
    "    X_data, y_data, cols = split_x_y_data(concat_df, n_timestamp)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=1, stratify=y_data) \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=(0.2+0.2*0.2), random_state=1, stratify=y_train) \n",
    "    cols = [textwrap.shorten(col, width=50, placeholder=\"...\") for col in cols]\n",
    "\n",
    "    y_train = y_train.reshape(-1)\n",
    "    y_test = y_test.reshape(-1)\n",
    "    y_val = y_val.reshape(-1)\n",
    "    print(len(y_train), len(y_val), len(y_test))\n",
    "    \n",
    "    # In[ ]:\n",
    "    \"\"\"\n",
    "        (5) split data (train : valid = 0.8 : 0.2)\n",
    "    \"\"\"\n",
    "    depth = n_timestamp\n",
    "\n",
    "    X_train_min, X_train_max = X_train.min(axis=0), X_train.max(axis=0)\n",
    "    y_train_min, y_train_max = y_train.min(axis=0), y_train.max(axis=0)\n",
    "\n",
    "    # In[ ]:\n",
    "    \"\"\"\n",
    "        (6) numpy to tensor\n",
    "    \"\"\"\n",
    "    X_train_t = torch.Tensor(X_train)\n",
    "    X_val_t = torch.Tensor(X_val)\n",
    "    X_test_t = torch.Tensor(X_test)\n",
    "    y_train_t = torch.Tensor(y_train)\n",
    "    y_val_t = torch.Tensor(y_val)\n",
    "    y_test_t = torch.Tensor(y_test)\n",
    "\n",
    "    # In[ ]:\n",
    "    \"\"\"\n",
    "        (7) make data loader \n",
    "    \"\"\"\n",
    "    train_loader = DataLoader(TensorDataset(X_train_t, y_train_t), batch_size=64, shuffle=True)\n",
    "    val_loader = DataLoader(TensorDataset(X_val_t, y_val_t), batch_size=64, shuffle=False)\n",
    "    test_loader = DataLoader(TensorDataset(X_test_t, y_test_t), batch_size=64, shuffle=False)\n",
    "\n",
    "    for x, y in train_loader:\n",
    "        print(y.shape)\n",
    "        break\n",
    "\n",
    "    # In[ ]:\n",
    "    \"\"\"\n",
    "        (8) define model & hyper parameters\n",
    "    \"\"\"\n",
    "    model = IMVFullLSTM(X_train_t.shape[2], 1, 128).to(device)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=params['learningrate'])\n",
    "    epoch_scheduler = torch.optim.lr_scheduler.StepLR(opt, 20, gamma=0.9)\n",
    "    \n",
    "    epochs = params[\"epochs\"]\n",
    "    patience = params[\"patience\"]\n",
    "    min_val_loss = params[\"min_val_loss\"]\n",
    "    loss = nn.MSELoss()\n",
    "    counter = 0\n",
    "\n",
    "    # In[ ]:\n",
    "    \"\"\"\n",
    "        (9) train dataset learning \n",
    "    \"\"\"\n",
    "    for i in range(epochs):\n",
    "        mse_train = 0\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            batch_x = batch_x.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "            opt.zero_grad()\n",
    "            y_pred, alphas, betas = model(batch_x)\n",
    "            y_pred = y_pred.squeeze(1)\n",
    "            l = loss(y_pred, batch_y)\n",
    "            l.backward()\n",
    "            mse_train += l.item()*batch_x.shape[0]\n",
    "            opt.step()\n",
    "        epoch_scheduler.step()\n",
    "        with torch.no_grad():\n",
    "            mse_val = 0\n",
    "            preds = []\n",
    "            true = []\n",
    "            for batch_x, batch_y in val_loader:\n",
    "                batch_x = batch_x.to(device)\n",
    "                batch_y = batch_y.to(device)\n",
    "                output, alphas, betas = model(batch_x)\n",
    "                output = output.squeeze(1)\n",
    "                preds.append(output.detach().cpu().numpy())\n",
    "                true.append(batch_y.detach().cpu().numpy())\n",
    "                mse_val += loss(output, batch_y).item()*batch_x.shape[0]\n",
    "        preds = np.concatenate(preds)\n",
    "        true = np.concatenate(true)\n",
    "        \n",
    "        if min_val_loss > mse_val**0.5:\n",
    "            min_val_loss = mse_val**0.5\n",
    "            print(\"Saving...\")\n",
    "            torch.save(model.state_dict(), \"{}/{}_model_state_dict.pt\".format(output_data_dir, outcome_name))\n",
    "            counter = 0\n",
    "        else: \n",
    "            counter += 1\n",
    "        \n",
    "        if counter == patience:\n",
    "            break\n",
    "        print(\"Iter: \", i, \"train: \", (mse_train/len(X_train_t))**0.5, \"val: \", (mse_val/len(X_val_t))**0.5)\n",
    "        if(i % 10 == 0):\n",
    "            preds = preds*(y_train_max - y_train_min) + y_train_min\n",
    "            true = true*(y_train_max - y_train_min) + y_train_min\n",
    "            mse = mean_squared_error(true, preds)\n",
    "            mae = mean_absolute_error(true, preds)\n",
    "            print(\"lr: \", opt.param_groups[0][\"lr\"])\n",
    "            print(\"mse: \", mse, \"mae: \", mae)\n",
    "            plt.figure(figsize=(20, 10))\n",
    "            plt.plot(preds)\n",
    "            plt.plot(true)\n",
    "            plt.show()\n",
    "\n",
    "    # In[ ]:\n",
    "    \"\"\"\n",
    "        (10) Test dataset evaluation\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        mse_val = 0\n",
    "        preds = []\n",
    "        true = []\n",
    "        alphas = []\n",
    "        betas = []\n",
    "        for batch_x, batch_y in test_loader:\n",
    "            batch_x = batch_x.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "            output, a, b = model(batch_x)\n",
    "            output = output.squeeze(1)\n",
    "            preds.append(output.detach().cpu().numpy())\n",
    "            true.append(batch_y.detach().cpu().numpy())\n",
    "            alphas.append(a.detach().cpu().numpy())\n",
    "            betas.append(b.detach().cpu().numpy())\n",
    "            mse_val += loss(output, batch_y).item()*batch_x.shape[0]\n",
    "    preds = np.concatenate(preds)\n",
    "    true = np.concatenate(true)\n",
    "    preds = preds*(y_train_max - y_train_min) + y_train_min\n",
    "    true = true*(y_train_max - y_train_min) + y_train_min\n",
    "    mse = mean_squared_error(true, preds)\n",
    "    mae = mean_absolute_error(true, preds)\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.plot(preds)\n",
    "    plt.plot(true)\n",
    "    plt.show()\n",
    "    alphas = np.concatenate(alphas)\n",
    "    betas = np.concatenate(betas)\n",
    "    alphas = alphas.mean(axis=0)\n",
    "    betas = betas.mean(axis=0)\n",
    "    alphas = alphas[..., 0]\n",
    "    betas = betas[..., 0]\n",
    "    alphas = alphas.transpose(1, 0)\n",
    "\n",
    "    recon = {}\n",
    "    recon['alphas'] = alphas\n",
    "    recon['betas'] = betas\n",
    "    recon['cols'] = cols\n",
    "    with open(output_data_dir.joinpath('figures.pickle'), 'wb') as f:\n",
    "        import pickle\n",
    "        pickle.dump(recon, f, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "    # In[ ]:\n",
    "    \"\"\"\n",
    "        (11) plotting heatmap\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(40, 30))\n",
    "    im = ax.imshow(alphas)\n",
    "    ax.set_xticks(np.arange(X_train_t.shape[1]))\n",
    "    ax.set_yticks(np.arange(len(cols)))\n",
    "    ax.set_xticklabels([\"t-\"+str(i) for i in np.arange(X_train_t.shape[1], 0, -1)])\n",
    "    ax.set_yticklabels(cols)\n",
    "    for i in range(len(cols)):\n",
    "        for j in range(X_train_t.shape[1]):\n",
    "            text = ax.text(j, i, round(alphas[i, j], 3),\n",
    "                        ha=\"center\", va=\"center\", color=\"w\")\n",
    "    ax.set_title(\"Importance of features and timesteps\")\n",
    "    #fig.tight_layout()\n",
    "    plt.savefig('{}/{}_heatmap_.png'.format(output_result_dir, outcome_name), format='png',\n",
    "                        dpi=300, facecolor='white', transparent=True,  bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    # In[ ]:\n",
    "    \"\"\"\n",
    "        (12) plotting feature importance\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 15))\n",
    "    plt.title(\"Feature importance\")\n",
    "    plt.barh(cols, betas)\n",
    "    plt.gca().invert_yaxis()\n",
    "    # plt.xticks(ticks=range(len(cols)), labels=list(cols), rotation=90)\n",
    "\n",
    "    plt.savefig('{}/{}_Feature_importance_.png'.format(output_result_dir, outcome_name), format='png',\n",
    "                        dpi=300, facecolor='white', transparent=True,  bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    y_true = true\n",
    "    y_pred_proba = preds\n",
    "    y_pred = np.rint(preds)\n",
    "\n",
    "    # In[ ]:\n",
    "    \"\"\"\n",
    "        (13) plotting feature importance\n",
    "    \"\"\"\n",
    "    confusion_matrix_figure2(y_true, y_pred, output_result_dir, outcome_name)\n",
    "    ROC_AUC(y_pred_proba, y_true, output_result_dir, outcome_name)\n",
    "    PR_AUC(y_pred_proba, y_true, output_result_dir, outcome_name)\n",
    "    model_performance_evaluation(y_true, y_pred, y_pred_proba, output_result_dir, outcome_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\"\"\"\n",
    "    For all drugs, perform the above tasks.\n",
    "\"\"\"\n",
    "for outcome_name in tqdm(cfg['drug'].keys()) :\n",
    "    try :\n",
    "        log.debug('drug : {}'.format(outcome_name))\n",
    "        runTask(outcome_name)\n",
    "    except :\n",
    "        traceback.print_exc()\n",
    "        log.error(traceback.format_exc())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "565e3544d5dbeb515a1265a05ceb357b4338ebedb8b2db99297d61f63f17eeee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
