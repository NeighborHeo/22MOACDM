{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. PS(Propensity score) Matching \n",
    "  * 1) Retrieve patient information from DB\n",
    "  * 2) PS Matched, and saved patients data in the local folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\"\"\"\n",
    "1) import package\n",
    "\"\"\"\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pathlib\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import traceback\n",
    "from tqdm import tqdm\n",
    "from datetime import timedelta\n",
    "\n",
    "from _utils.customlogger import customlogger as CL\n",
    "from _utils.preprocessing import *\n",
    "from _utils.psmatch import *\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)  #각 컬럼 width 최대로 \n",
    "pd.set_option('display.max_rows', 50)      # display 50개 까지 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\"\"\"\n",
    "2) loading config\n",
    "\"\"\"\n",
    "current_dir = pathlib.Path.cwd()\n",
    "parent_dir = current_dir.parent\n",
    "with open(parent_dir.joinpath(\"config.json\")) as file:\n",
    "    cfg = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\"\"\"\n",
    "3) load information \n",
    "\"\"\"\n",
    "working_date = cfg[\"working_date\"]\n",
    "curr_file_name = os.path.splitext(os.path.basename(os.path.abspath('')))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\"\"\"\n",
    "4) create Logger\n",
    "\"\"\"\n",
    "log = CL(\"custom_logger\")\n",
    "pathlib.Path.mkdir(pathlib.Path('{}/_log/'.format(parent_dir)), mode=0o777, parents=True, exist_ok=True)\n",
    "log = log.create_logger(file_name=\"../_log/{}.log\".format(curr_file_name), mode=\"a\", level=\"DEBUG\")  \n",
    "log.debug('start {}'.format(curr_file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # In[ ]:\n",
    "# \"\"\"\n",
    "# 5) connection DataBase\n",
    "# \"\"\"\n",
    "# if (cfg[\"dbms\"]==\"postgresql\"):\n",
    "#     db_cfg = cfg[\"postgresql\"]\n",
    "#     import psycopg2 as pg\n",
    "#     conn = pg.connect(host=db_cfg['@server'], user=db_cfg['@user'], password=db_cfg['@password'], port=db_cfg['@port'], dbname=db_cfg['@database']) \n",
    "#     log.debug(\"postgresql connect\")\n",
    "    \n",
    "# elif (cfg[\"dbms\"]==\"mssql\"):\n",
    "#     db_cfg = cfg[\"mssql\"]\n",
    "#     import pymssql\n",
    "#     conn= pymssql.connect(server=db_cfg['@server'], user=db_cfg['@user'], password=db_cfg['@password'], port=db_cfg['@port'], database=db_cfg['@database'], as_dict=False)\n",
    "#     log.debug(\"mssql connect\")\n",
    "    \n",
    "# else:\n",
    "#     log.warning(\"set config.json - sql - dbms : mssql or postgresql\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "5) connection DataBase\n",
    "\"\"\"\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "driver = cfg[\"dbms\"]\n",
    "db_cfg = cfg[driver]\n",
    "username = db_cfg[\"@user\"]\n",
    "password = db_cfg[\"@password\"]\n",
    "host = db_cfg[\"@server\"]\n",
    "port = db_cfg[\"@port\"]\n",
    "database = db_cfg[\"@database\"]\n",
    "if cfg[\"dbms\"] == \"mssql\":\n",
    "    sqldriver = \"mssql+pymssql\"\n",
    "elif cfg[\"dbms\"] == \"postgresql\":\n",
    "    sqldriver = \"postgresql+psycopg2\"\n",
    "url = f\"{sqldriver}://{username}:{password}@{host}:{port}/{database}\"\n",
    "engine = create_engine(url, echo=False)\n",
    "sessionlocal = sessionmaker(autocommit=False, autoflush=True, bind=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runTask(outcome_name):\n",
    "    \"\"\"\n",
    "        Propensity Score Matching\n",
    "    \"\"\"\n",
    "    output_data_dir = pathlib.Path('{}/data/{}/importsql/{}/'.format(parent_dir, working_date, outcome_name))\n",
    "    output_result_dir = pathlib.Path('{}/result/{}/importsql/{}/'.format(parent_dir, working_date, outcome_name))\n",
    "    pathlib.Path.mkdir(output_data_dir, mode=0o777, parents=True, exist_ok=True)\n",
    "    pathlib.Path.mkdir(output_result_dir, mode=0o777, parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "    # In[ ]:\n",
    "    \"\"\"\n",
    "        (0) Only the measurement concept IDs used to extract side effects are extracted. To match PS (Propensity Score)\n",
    "    \"\"\"\n",
    "    outcome_lab_list = []\n",
    "    if 'nephrotoxicity' == cfg['drug'][outcome_name]['ade'] :\n",
    "        concept_id_CR = int(cfg['meas'][\"CR\"]['@meas_concept_id'])\n",
    "        outcome_lab_list = [concept_id_CR]\n",
    "    else :\n",
    "        concept_id_AST = int(cfg['meas'][\"AST\"]['@meas_concept_id'])\n",
    "        concept_id_ALT = int(cfg['meas'][\"ALT\"]['@meas_concept_id'])\n",
    "        concept_id_ALP = int(cfg['meas'][\"ALP\"]['@meas_concept_id'])\n",
    "        concept_id_TB = int(cfg['meas'][\"TB\"]['@meas_concept_id'])\n",
    "        outcome_lab_list = [concept_id_AST, concept_id_ALT, concept_id_ALP, concept_id_TB]\n",
    "    outcome_lab_list_str = ','.join([str(i) for i in outcome_lab_list])\n",
    "    print(outcome_lab_list_str)\n",
    "\n",
    "    # In[ ]:\n",
    "    \"\"\"\n",
    "        (1) set table name and Execute a query to read a table\n",
    "    \"\"\"\n",
    "    tnPopulation = '{}.person_{}'.format(db_cfg[\"@person_database_schema\"], outcome_name)\n",
    "    tnMeasurement = '{}.measurement'.format(db_cfg[\"@cdm_database_schema\"])\n",
    "\n",
    "    sql_person_query = f\"\"\"\n",
    "    SELECT * FROM {tnPopulation}\n",
    "    \"\"\"\n",
    "    \n",
    "    sql_meas_query = f\"\"\"\n",
    "    SELECT person_id, measurement_concept_id, measurement_date, value_as_number, range_low, range_high \n",
    "    FROM {tnMeasurement}\n",
    "    WHERE measurement_concept_id in ({outcome_lab_list_str})\n",
    "    AND value_as_number IS NOT NULL\n",
    "    AND person_id IN (SELECT person_id FROM {tnPopulation});\n",
    "    \"\"\"\n",
    "\n",
    "    person_df = pd.read_sql(sql=sql_person_query, con=engine)\n",
    "    meas_df = pd.read_sql(sql=sql_meas_query, con=engine)\n",
    "\n",
    "    # In[ ]:\n",
    "    \"\"\"\n",
    "        (2) Convert gender to sex columns to 0,1\n",
    "            : Change the column name to sex and display 0 for female and 1 for male\n",
    "    \"\"\"\n",
    "    def convert_gender_column(_df, inplace=False):\n",
    "        df = _df if inplace==True else _df.copy()\n",
    "        \n",
    "        if 'gender_source_concept_id' in df.columns and df['gender_source_concept_id'].notnull().all():\n",
    "            print(\"selected gender_source_concept_id\")\n",
    "            df.rename(columns={'gender_source_concept_id':'sex'}, inplace=True)\n",
    "            df['sex'].replace(8532, 0, inplace=True)\n",
    "            df['sex'].replace(8507, 1, inplace=True)\n",
    "        elif 'gender_source_value' in df.columns and df['gender_source_value'].notnull().all():\n",
    "            print(\"selected gender_source_value\")\n",
    "            df.rename(columns={'gender_source_value':'sex'}, inplace=True)\n",
    "            df['sex'].replace(['F', 'Female'], 0, inplace=True)\n",
    "            df['sex'].replace(['M', 'Male'], 1, inplace=True)\n",
    "        else :\n",
    "            print(\"The gender column has already been changed, there is no column, or the data is null.\")\n",
    "        return df\n",
    "    \n",
    "    person_df = convert_gender_column(person_df)\n",
    "    \n",
    "    # In[ ]:\n",
    "    \"\"\"\n",
    "        (4) Label 1 if the first abnormal date value exists, 0 if not.\n",
    "    \"\"\"\n",
    "    person_df['label'] = (~person_df['first_abnormal_date'].isnull()).astype(int)\n",
    "\n",
    "    # concat할 수 있도록 column name 통일시켜주기\n",
    "    meas_df.rename(columns={'measurement_concept_id':'concept_id','measurement_date':'concept_date','value_as_number':'concept_value'}, inplace=True)\n",
    "\n",
    "    # In[ ]:\n",
    "    \"\"\"\n",
    "        (6) Remove duplicate data\n",
    "    \"\"\"\n",
    "    def drop_duplicates_(domain_df):\n",
    "        n_prev = len(domain_df)\n",
    "        domain_df = domain_df.drop_duplicates()\n",
    "        n_next = len(domain_df)\n",
    "        print('{}>{}'.format(n_prev, n_next))\n",
    "        return domain_df\n",
    "    meas_df = drop_duplicates_(meas_df)\n",
    "\n",
    "    # In[ ]:\n",
    "    \"\"\"\n",
    "        (7) person(+cohort) + measurement table\n",
    "    \"\"\"\n",
    "    meas_df = pd.merge(person_df, meas_df, left_on=[\"person_id\"], right_on=[\"person_id\"], how=\"inner\").reset_index(drop=True)\n",
    "    meas_df = cohortConditionSetting(meas_df, pre_observation_period=60, post_observation_peroid=60, delDataAfterAbnormal=True)\n",
    "    psm_data_df = meas_df.loc[meas_df['concept_id'].isin(outcome_lab_list)]\n",
    "    \n",
    "    # In[ ]:\n",
    "    \"\"\"\n",
    "        (9) Pivoting Lab Data Rows to Columns\n",
    "    \"\"\"\n",
    "    psm_data_df = psm_data_df.query('concept_date <= cohort_start_date')\n",
    "    psm_data_df = pd.pivot_table(data=psm_data_df, index=['person_id', 'age', 'sex', 'label'], columns='concept_id', values='concept_value').reset_index().rename_axis(None, axis=1)\n",
    "    psm_data_df.columns = psm_data_df.columns.astype(str)\n",
    "    print(psm_data_df.head(), psm_data_df.dtypes)\n",
    "\n",
    "    # In[ ]:\n",
    "    \"\"\"\n",
    "        (10) PS (Propensity Score) Matching with KNN Match algorithm using psmpy library\n",
    "    \"\"\"\n",
    "    psm_data_df = psm_data_df.dropna()\n",
    "    # covarates = columns - person_id, label \n",
    "    covarates = list(set(psm_data_df.columns) - {'person_id', 'label'})\n",
    "    matched_df = get_matching_multiple_pairs(psm_data_df, treatments='label', covariates=covarates, n_neighbors=3)\n",
    "\n",
    "    # In[ ]:\n",
    "    \"\"\"\n",
    "        (11) Filtered by PSMatched patient IDs and saved as a file\n",
    "    \"\"\"\n",
    "    psm_person_ids = matched_df.person_id.values\n",
    "    person_df = pd.read_sql(sql=sql_person_query, con=engine)\n",
    "    psm_person_df = person_df.loc[person_df.person_id.isin(psm_person_ids)].reset_index(drop=True)\n",
    "    psm_person_df.to_sql(name=f\"person_{outcome_name.lower()}_psm\", schema=cfg[driver][\"@person_database_schema\"], con=engine, if_exists='replace', index=False)\n",
    "    \n",
    "    psm_person_df.to_csv(output_data_dir.joinpath('psm_person_df.txt'),index=False)\n",
    "    import pickle\n",
    "    with open(output_data_dir.joinpath('psm_person_ids.pkl'), 'wb') as f:\n",
    "        pickle.dump(psm_person_ids, f)\n",
    "        \n",
    "    for cov in covarates:\n",
    "        print(f'covariate: {cov}')\n",
    "        p_value = user_t_test_ind(matched_df, 'label', cov)\n",
    "        print(\"cov : {} / p value: {}\".format(cov, p_value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[ ]:\n",
    "\"\"\"\n",
    "    For all drugs, perform the above tasks.\n",
    "\"\"\"\n",
    "for outcome_name in tqdm(cfg['drug'].keys()) :\n",
    "    try :\n",
    "        log.debug('drug : {}'.format(outcome_name))\n",
    "        runTask(outcome_name)\n",
    "    except :\n",
    "        traceback.print_exc()\n",
    "        log.error(traceback.format_exc())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.dispose()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "65a9df8dabcfad470e190f31aab646891f837e6d422cdbd7188428f094f05b09"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
